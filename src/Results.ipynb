{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -mpip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "import _init_paths\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import argparse\n",
    "from Metrics import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from train_utils import *\n",
    "# from Data2array import *\n",
    "from pose_code.hourglass import hg\n",
    "from pose_code.atthourglass import atthg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import peak_local_max\n",
    "import skimage\n",
    "import pickle\n",
    "import colorsys\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.extmath import cartesian\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "def save_test_results(inputs, outputs, targets, name='', target_th=0.5):\n",
    "    clr_vis_Y = []\n",
    "    hues = np.linspace(0, 179, targets.shape[1], dtype=np.uint8)\n",
    "    blank_ch = 255*np.ones_like(targets[0,0], dtype=np.uint8)\n",
    "\n",
    "    for Y in [targets, outputs]:\n",
    "        for y, x in zip(Y, inputs):\n",
    "            y_colored = np.zeros([y.shape[1], y.shape[2], 3], dtype=np.uint8)\n",
    "            y_all = np.zeros([y.shape[1], y.shape[2]], dtype=np.uint8)\n",
    "            \n",
    "            for ych, hue_i in zip(y, hues):\n",
    "                ych = ych/np.max(np.max(ych))\n",
    "                ych[np.where(ych<target_th)] = 0\n",
    "                # ych = cv2.GaussianBlur(ych,(15,15),cv2.BORDER_DEFAULT)\n",
    "\n",
    "                ych_hue = np.ones_like(ych, dtype=np.uint8)*hue_i\n",
    "                ych = np.uint8(255*ych/np.max(ych))\n",
    "\n",
    "                colored_ych = np.zeros_like(y_colored, dtype=np.uint8)\n",
    "                colored_ych[:, :, 0] = ych_hue\n",
    "                colored_ych[:, :, 1] = blank_ch\n",
    "                colored_ych[:, :, 2] = ych\n",
    "                colored_y = cv2.cvtColor(colored_ych, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "                y_colored += colored_y\n",
    "                y_all += ych\n",
    "\n",
    "            x = np.moveaxis(x, 0, -1)\n",
    "            x = x/np.max(x)*255\n",
    "\n",
    "            x_3ch = np.zeros([x.shape[0], x.shape[1], 3])\n",
    "            for i in range(3):\n",
    "                x_3ch[:, :, i] = x[:, :, 0]\n",
    "\n",
    "            img_mix = np.uint8(x_3ch*0.5 + y_colored*0.5)\n",
    "            # img_mix = cv2.cvtColor(img_mix, cv2.COLOR_BGR2RGB)\n",
    "            clr_vis_Y.append(img_mix)\n",
    "\n",
    "    \n",
    "    t = np.array(clr_vis_Y)\n",
    "    t = np.transpose(t, [0, 3, 1, 2])\n",
    "    trgts = make_grid(torch.Tensor(t), nrow=4)\n",
    "\n",
    "    txt = f'../visualize/{name}_test_result.png'\n",
    "    res = np.transpose(trgts.numpy(), (1,2,0))\n",
    "    cv2.imwrite(txt, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Verterbal disc labeling using pose estimation')\n",
    "    \n",
    "## Parameters\n",
    "datapathds = '../prepared_dataset/prepared_testset_t1_ds'\n",
    "datapathfull='../prepared_dataset/prepared_testset_t1_full'              \n",
    "modality='t1'                                               \n",
    "njoints=11\n",
    "resume= False\n",
    "att= True\n",
    "stacks=2\n",
    "blocks=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "idtest = 1\n",
    "def extract_skeleton(inputs, outputs, target, target_th=0.4):\n",
    "    global idtest\n",
    "    outputs  = outputs.data.cpu().numpy()\n",
    "    target  = target.data.cpu().numpy()\n",
    "    inputs = inputs.data.cpu().numpy()\n",
    "    skeleton_images = []\n",
    "    for idx in range(outputs.shape[0]):    \n",
    "        count_list = []\n",
    "        Nch = 0\n",
    "        center_list = {}\n",
    "        while np.sum(np.sum(target[idx, Nch]))>0:\n",
    "              Nch += 1       \n",
    "        for idy in range(Nch): \n",
    "            ych = outputs[idx, idy]\n",
    "            ych = np.rot90(ych)\n",
    "            ych = ych/np.max(np.max(ych))\n",
    "            ych[np.where(ych<target_th)] = 0\n",
    "            ych = np.where(ych>0, 1.0, 0)\n",
    "            ych = np.uint8(ych)\n",
    "            num_labels, labels_im, states, centers = cv2.connectedComponentsWithStats(ych)\n",
    "            count_list.append(num_labels-1)\n",
    "            center_list[str(idy)] = [t[::-1] for t in centers[1:]]\n",
    "            \n",
    "        ups = []\n",
    "        for c in count_list:\n",
    "            ups.append(range(c))\n",
    "        combs = cartesian(ups)\n",
    "        \n",
    "        best_loss = np.Inf\n",
    "        best_skeleton = []\n",
    "        for comb in combs:\n",
    "            cnd_skeleton = []\n",
    "            for joint_idx, cnd_joint_idx in enumerate(comb):\n",
    "                cnd_center = center_list[str(joint_idx)][cnd_joint_idx]\n",
    "                cnd_skeleton.append(cnd_center)\n",
    "            loss = check_skeleton(cnd_skeleton, norm_mean_skeleton)\n",
    "            if best_loss > loss:\n",
    "                best_loss = loss\n",
    "                best_skeleton = cnd_skeleton\n",
    "        \n",
    "        hits = np.zeros_like(outputs[0])\n",
    "        for i, jp, in enumerate(best_skeleton):\n",
    "            jp = [int(t) for t in jp]\n",
    "            hits[i, jp[0]-1:jp[0]+2, jp[1]-1:jp[1]+2] = [255, 255, 255]\n",
    "            hits[i, :, :] = cv2.GaussianBlur(hits[i, :, :],(5,5),cv2.BORDER_DEFAULT)\n",
    "            hits[i, :, :] = hits[i, :, :]/hits[i, :, :].max()*255\n",
    "        \n",
    "        skeleton_images.append(hits)\n",
    "        \n",
    "    skeleton_images = np.array(skeleton_images)\n",
    "    inputs = np.rot90(inputs, axes=(-2, -1))\n",
    "    target = np.rot90(target, axes=(-2, -1))\n",
    "    save_test_results(inputs, skeleton_images, targets=target, name=idtest, target_th=0.5)\n",
    "    idtest+=1\n",
    "    return skeleton_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skeleton(cnd_sk, mean_skeleton):\n",
    "    cnd_sk = np.array(cnd_sk)\n",
    "    Normjoint = np.linalg.norm(cnd_sk[0]-cnd_sk[4])\n",
    "    for idx in range(1, len(cnd_sk)):\n",
    "        cnd_sk[idx] = (cnd_sk[idx] - cnd_sk[0]) / Normjoint\n",
    "    cnd_sk[0] -= cnd_sk[0]\n",
    "    \n",
    "    return np.sum(np.linalg.norm(mean_skeleton[:len(cnd_sk)]-cnd_sk))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load image\n",
      "retrieving ground truth coordinates\n",
      "(39, 320, 320, 1) (39, 320, 320, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3035: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/data/datafast1/DNS/newcode/src/train_utils.py:320: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ych = ych/np.max(np.max(ych))\n",
      "/data/datafast1/DNS/newcode/src/train_utils.py:321: RuntimeWarning: invalid value encountered in less\n",
      "  ych[np.where(ych<target_th)] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 1034, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in less\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n",
      "(518, 1034, 3)\n"
     ]
    }
   ],
   "source": [
    "# main script\n",
    "\n",
    "args = parser.parse_known_args()\n",
    "norm_mean_skeleton = np.load('../prepared_dataset/T1_Skelet.npy')\n",
    "\n",
    "global cuda_available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print('load image')\n",
    "\n",
    "with open(datapathds, 'rb') as file_pi:\n",
    "     ds = pickle.load(file_pi)\n",
    "with open(datapathfull, 'rb') as file_pi:\n",
    "     full = pickle.load(file_pi)            \n",
    "full[0] = full[0][:, :, :, :, 0]\n",
    "print('retrieving ground truth coordinates')\n",
    "\n",
    "# coord_gt = retrieves_gt_coord(ds)\n",
    "# intialize metrics\n",
    "global distance_l2\n",
    "global zdis\n",
    "global faux_pos\n",
    "global faux_neg\n",
    "global tot\n",
    "distance_l2 = []\n",
    "zdis = []\n",
    "faux_pos = []\n",
    "faux_neg = []\n",
    "tot = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if att:\n",
    "    model = atthg(num_stacks=stacks, num_blocks=blocks, num_classes=njoints)\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.load_state_dict(torch.load(f'../weights/model_{modality}_att', map_location='cpu')['model_weights'])\n",
    "else:\n",
    "    model = hg(num_stacks=stacks, num_blocks=blocks, num_classes=njoints)\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.load_state_dict(torch.load(f'../weights/model_simple_{modality}_att', map_location='cpu')['model_weights'])\n",
    "\n",
    "\n",
    "## Get the visualization resutls of the test set\n",
    "print(full[0].shape, full[1].shape)\n",
    "full_dataset_test = image_Dataset(image_paths=full[0],target_paths=full[1], use_flip = False)\n",
    "MRI_test_loader   = DataLoader(full_dataset_test, batch_size= 4, shuffle=False, num_workers=0)\n",
    "model.eval()\n",
    "for i, (input, target, vis) in enumerate(MRI_test_loader):\n",
    "    input, target = input.to(device), target.to(device, non_blocking=True)\n",
    "    output = model(input) \n",
    "    output = output[-1]\n",
    "    save_epoch_res_as_image2(input, output, target, epoch_num=i+1, target_th=0.5, pretext= True)\n",
    "    extract_skeleton(input, output, target)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(53.55555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
